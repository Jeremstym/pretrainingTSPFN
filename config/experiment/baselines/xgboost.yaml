# @package _global_

defaults:
  # - /task/model/prediction_head: pfn-prediction
  # - /task/model/encoder: tspfn-encoder
  # # - /task/model/loc_head: channel-loc
  - override /task/model: null
  - override /task/optim: adamw
  - override /data: evaluating-ecg5000



test: True
trainer:
  devices: ${sys.num_gpus:}
  accelerator: gpu
  precision: 32 #16-mixed, 32
  
output_dir: ${sys.getcwd:}

data:
  batch_size: null
  num_workers: 4 # try 4, 8, 16 depending on the system capabilities

task:
  _target_: tspfn.baselines.xgboost.XGBoostStaticBaseline
  num_classes: ${data.num_classes}
  xgb_params:
    n_estimators: 200
    max_depth: 6
    learning_rate: 0.1
    tree_method: "hist"  # Use "gpu_hist" if using a GPU-enabled XGBoost
    device: "cuda"
    verbosity: 0
    objective: "multi:softprob"
  # optim:
  #   optimizer:
  #     _target_: torch.optim.AdamW
  #     lr: 1e-4

# Change checkpoint loading defaults to:
ckpt: ??? # Make it mandatory to provide a checkpoint
weights_only: True  # Only load the weights and ignore the hyperparameters
strict: True # Only load weights where they match the defined network, to only some changes (e.g. heads, etc.)


experiment_dirname: data=${hydra:runtime.choices.task/data}/contrastive=${oc.select:task.contrastive_loss_weight,0}/time_series_tokenizer=${hydra:runtime.choices.task/time_series_tokenizer/model}
hydra:
  job:
    config:
      override_dirname:
        exclude_keys:
          - hydra/launcher
          - hydra.launcher.n_jobs
          - hydra.run.dir
          - hydra.sweep.dir
          - hydra.sweep.subdir

          - experiment
          - trainer.enable_progress_bar
          - trainer.max_epochs

          - callbacks.learning_rate_finder

          - ckpt

          - data
          - task.predict_losses

          - task.embed_dim
          - task/time_series_tokenizer/model

          - task/model/encoder
